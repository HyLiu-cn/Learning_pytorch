{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09616bc2",
   "metadata": {},
   "source": [
    "### :\n",
    "    通过 nvidia-smi 命令来查看显卡信息了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1493ab",
   "metadata": {},
   "source": [
    "### 计算设备:\n",
    "    指定用来存储和计算的设备，如使用内存的CPU或者使用显存的GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2b19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1271d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用 torch.cuda.is_available() 查看GPU是否可用\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee96bdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看GPU数量\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc5cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前GPU索引号，索引号从0开始\n",
    "# torch.cuda.current_device()\n",
    "\n",
    "# 根据索引号查看GPU名字\n",
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd3571",
   "metadata": {},
   "source": [
    "### Tensor的GPU计算:\n",
    "    使用 .cuda() 可以将 CPU 上的 Tensor 转换（复制）到GPU上\n",
    "        如果有多块 GPU，我们用 .cuda(i) 来表示第 i 块 GPU 及相应的显存（ i 从 0 开始）且 cuda(0) 和 cuda() 等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23381ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99479b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = x.cuda(device=0)\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf0c07",
   "metadata": {},
   "source": [
    "##### \n",
    "    可以通过 Tensor 的 device 属性来查看该 Tensor 所在的设备\n",
    "    也可以直接在创建的时候通过 device 就指定设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f738532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910a2b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,  11, 111])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x_1 = torch.tensor([1,11,111],device=device) # 等价于 torch.tensor([1,11,111]).to(device)\n",
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396df08e",
   "metadata": {},
   "source": [
    "#### \n",
    "    存储在不同位置中的数据是不可以直接进行计算的\n",
    "        即存放在 CPU 上的数据不可以直接与存放在 GPU 上的数据进行运算，位于不同 GPU 上的数据也是不能直接进行计算的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec17d5",
   "metadata": {},
   "source": [
    "### 模型的GPU计算\n",
    "    同Tensor类似，模型也可以通过 .cuda() 转换到 GPU 上\n",
    "        还可以通过检查模型的参数的 device 属性来查看存放模型的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b6573dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2,1)\n",
    ")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2df08ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net[0].parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b6bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换到GPU上\n",
    "# net.cuda()\n",
    "# list(net[0].parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd88bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
