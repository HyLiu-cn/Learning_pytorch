{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28896b32",
   "metadata": {},
   "source": [
    "### :\n",
    "    定义单隐藏层的多层感知机，使用默认方式初始化它的参数，并做一次前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86fbcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "975121fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4,3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(3,1)\n",
    ")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76740255",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,4)\n",
    "y = net(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4986f2c",
   "metadata": {},
   "source": [
    "#### 访问模型参数:\n",
    "    可以通过Module类的 parameters()或者 named_parameters() 方法来访问所有参数（以迭代器的形式返回）\n",
    "        后者除了返回参数 Tensor 外,还返回其对应的参数名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5afd9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "name:0.weight \t param size:torch.Size([3, 4])\n",
      "name:0.bias \t param size:torch.Size([3])\n",
      "name:2.weight \t param size:torch.Size([1, 3])\n",
      "name:2.bias \t param size:torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(type(net.named_parameters()))\n",
    "for name,param in net.named_parameters():\n",
    "    print('name:{} \\t param size:{}'.format(name,param.size()))\n",
    "#     可见返回的名字自动加上了层数的索引作为前缀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16ebac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([3, 4])\n",
      "bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 访问net中单层的参数\n",
    "for name,param in net[0].named_parameters():\n",
    "    print(name,param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef16052",
   "metadata": {},
   "source": [
    "##### \n",
    "    返回的 param 的类型为torch.nn.parameter.Parameter\n",
    "        是Tensor的子类，与Tensor不同的是如果一个 Tensor 是 Parameter，那么它会自动被添加到模型的参数列表里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4c2490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.weight_1 = torch.nn.Parameter(torch.rand(2,2))\n",
    "        self.weight_2 = torch.rand(2,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1efb3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Net()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7386123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_1 torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "for name,param in n.named_parameters():\n",
    "    print(name,param.size()) # weight_1 在参数列表中，而weight_2未被添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf6a4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2292,  0.4193, -0.4085,  0.2712],\n",
      "        [-0.3930,  0.4300,  0.1579,  0.1826],\n",
      "        [ 0.3080, -0.3230, -0.0028,  0.1972]])\n",
      "None\n",
      "tensor([[-0.4358, -0.6243, -0.5315, -0.2189],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3779,  0.5413,  0.4608,  0.1898]])\n"
     ]
    }
   ],
   "source": [
    "# Parameter是Tensor，即 拥有 Tensor 所有属性\n",
    "weight = list(net[0].parameters())[0]\n",
    "print(weight.data)\n",
    "print(weight.grad) # 反向传播前梯度为None\n",
    "y.backward()\n",
    "print(weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b76c2c",
   "metadata": {},
   "source": [
    "#### 初始化模型参数\n",
    "    虽然 nn.Module 的模块参数都采取了较为合理的初始化策略\n",
    "        但通常需要使用其他方法来初始化权重，torch.nn.init 模块里提供了多种预设的初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6b20440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-3.7858e-03,  1.0640e-02,  1.5413e-03,  1.4263e-03],\n",
      "        [ 1.7665e-03,  1.0520e-05,  1.4230e-02, -1.8256e-03],\n",
      "        [ 2.3419e-02, -4.2842e-03,  6.1279e-03,  1.6328e-02]])\n",
      "2.weight tensor([[-0.0008,  0.0018, -0.0026]])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        torch.nn.init.normal_(param,mean=0,std=0.01)\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0e2a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化前: tensor([-0.0562, -0.4443,  0.1757])\n",
      "初始化后: tensor([0., 0., 0.])\n",
      "初始化前: tensor([-0.3594])\n",
      "初始化后: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        print('初始化前:',param.data)\n",
    "        torch.nn.init.constant_(param,val=0)\n",
    "        print('初始化后:',param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ba5bb",
   "metadata": {},
   "source": [
    "#### 自定义初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de274b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight_(tensor):\n",
    "    # 就是一个inplace改变Tensor值的函数，而且这个过程是不记录梯度的\n",
    "    with torch.no_grad():\n",
    "        tensor.uniform_(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185e2d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-3.7858e-03,  1.0640e-02,  1.5413e-03,  1.4263e-03],\n",
      "        [ 1.7665e-03,  1.0520e-05,  1.4230e-02, -1.8256e-03],\n",
      "        [ 2.3419e-02, -4.2842e-03,  6.1279e-03,  1.6328e-02]])\n",
      "0.weight tensor([[2.0285, 4.9196, 0.6261, 1.5578],\n",
      "        [3.2110, 1.9888, 2.0549, 3.2557],\n",
      "        [3.6277, 3.0509, 4.8495, 4.8336]])\n",
      "2.weight tensor([[-0.0008,  0.0018, -0.0026]])\n",
      "2.weight tensor([[4.6753, 0.9803, 1.4547]])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(name,param.data)\n",
    "        init_weight_(param)\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f494f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.bias tensor([0., 0., 0.])\n",
      "0.bias tensor([1., 1., 1.])\n",
      "2.bias tensor([0.])\n",
      "2.bias tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# 还可以通过改变这些参数的data来改写模型参数值同时不会影响梯度\n",
    "for name,param in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        print(name,param.data)\n",
    "        param.data += 1\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771d688",
   "metadata": {},
   "source": [
    "#### 共享模型参数\n",
    "    希望在多个层之间共享模型参数\n",
    "    可以通过 Module 类的 forward 函数里多次调用同一个层\n",
    "    此外，传入 Sequential 的模块是同一个 Module 实例的话参数也是共享的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c576b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear = torch.nn.Linear(1,1,bias=True)\n",
    "net = torch.nn.Sequential(linear,linear)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc114625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[0.6267]])\n",
      "0.bias tensor([0.4458])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59e821a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18bb6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net[0] == net[1])\n",
    "net[0].weight == net[1].weight\n",
    "# 这两个线性层其实一个对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc5fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
