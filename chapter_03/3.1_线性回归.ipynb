{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003ba2b5",
   "metadata": {},
   "source": [
    "### :\n",
    "    线性回归输出是一个连续值，因此适用于回归问题\n",
    "    如预测房屋价格、气温、销售额等连续值的问题\n",
    "    \n",
    "    与回归问题不同，分类问题中模型的最终输出是一个离散值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00fe17c",
   "metadata": {},
   "source": [
    "### 线性回归基本要素:\n",
    "    模型定义\n",
    "    模型训练：训练数据、损失函数、优化算法\n",
    "    模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb543358",
   "metadata": {},
   "source": [
    "### 线性回归-从零开始实现：\n",
    "    只利用Tensor和autograd来实现一个线性回归的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fecb7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c0a34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run d2lzh_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140ee45",
   "metadata": {},
   "source": [
    "#### 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97ea7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "x = torch.randn(num_examples,num_inputs,dtype=torch.float32)\n",
    "true_w = [2,-3.4]\n",
    "true_b = 4.2\n",
    "y = true_w[0] * x[:,0] + true_w[1] * x[:,1] + true_b\n",
    "y += torch.tensor(np.random.normal(0,0.01,size=y.size()),dtype=torch.float32) # 噪声\n",
    "# num_inputs = 2\n",
    "# num_examples = 1000\n",
    "# true_w = [2, -3.4]\n",
    "# true_b = 4.2\n",
    "# features = torch.randn(num_examples, num_inputs,\n",
    "#                        dtype=torch.float32)\n",
    "# labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "# labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n",
    "#                        dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac72f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0557, -2.0816]), tensor(11.1734))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80233e",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "977fc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size,features,labels): # 相当于 DataLoader\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices) # # 样本的读取顺序是随机的\n",
    "    for i in range(0,num_examples,batch_size):\n",
    "        j = torch.LongTensor(indices[i : min(i + batch_size,num_examples)]) # 最后一次可能不足一个batch\n",
    "        yield features.index_select(0, j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a96ece19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9200,  1.4616],\n",
      "        [-1.1124,  0.1067],\n",
      "        [ 0.4409,  0.0234],\n",
      "        [ 0.3691,  0.7310],\n",
      "        [-0.5627,  0.4252],\n",
      "        [-0.3944,  0.8510],\n",
      "        [ 0.1661,  1.1447],\n",
      "        [-0.7260, -0.9729],\n",
      "        [ 0.9932,  0.4820],\n",
      "        [ 0.6249,  0.7272]]) tensor([-2.6004,  1.6076,  4.9968,  2.4506,  1.6301,  0.5161,  0.6347,  6.0586,\n",
      "         4.5370,  2.9787])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for x,y in data_iter(batch_size,x,y):\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1240ce",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77f2d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将权重初始化成均值为0、标准差为0.01的正态随机数，偏差则初始化成0\n",
    "w = torch.tensor(np.random.normal(0,0.01,(num_inputs,1)),dtype=torch.float32)\n",
    "b = torch.zeros(1,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b0a72f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f39bd",
   "metadata": {},
   "source": [
    "#### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba0476e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linrg(x,w,b):\n",
    "#     使用mm函数做矩阵乘法\n",
    "#     return torch.mm(x,w) + b\n",
    "    return x @ w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf87da9",
   "metadata": {},
   "source": [
    "#### 定义损失函数\n",
    "![mse_loss](./img/3.1/mse_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc932061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平方损失来定义线性回归的损失函数\n",
    "def squared_loss(y_predict,y):\n",
    "    return ((y_predict - y.view(y_predict.size()))**2 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdcf29",
   "metadata": {},
   "source": [
    "#### 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5e26eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    for param in params:\n",
    "        param.data -= param.grad * lr / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33856ad2",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7366a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.03\n",
    "loss_fn = squared_loss\n",
    "optimizer = sgd\n",
    "model = linrg\n",
    "batch_size = 10\n",
    "params = [w,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fdc3f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0046],\n",
       "         [-0.0225]], requires_grad=True),\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbc36b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 5.322900\n",
      "epoch 2, loss 5.168851\n",
      "epoch 3, loss 5.022611\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for x_1,y_1 in data_iter(batch_size,x,y):\n",
    "        l = loss_fn(model(x_1,w,b),y_1).sum()\n",
    "#         if params is not None and params[0].grad is not None:\n",
    "#             for param in params:\n",
    "#                 param.grad.data.zero_()\n",
    "\n",
    "        l.backward()\n",
    "        sgd([w,b],lr,batch_size)\n",
    "        \n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "        \n",
    "    train_l = loss_fn(model(x,w,b),y)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b75dbb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] \n",
      " tensor([[ 0.0465],\n",
      "        [-0.0366]], requires_grad=True)\n",
      "4.2 \n",
      " tensor([0.2005], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(true_w, '\\n', w)\n",
    "print(true_b, '\\n', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39614799",
   "metadata": {},
   "source": [
    "### 线性回归的简洁实现:\n",
    "    torch.utils.data模块提供了有关数据处理的工具\n",
    "    torch.nn模块定义了大量神经网络的层\n",
    "    torch.nn.init模块定义了各种初始化方法\n",
    "    torch.optim模块提供了很多常用的优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99de08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import init,Module,Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0ad90",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4cf32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(x,y)\n",
    "data_iter_1 = DataLoader(dataset,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50d1c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1124,  0.1067],\n",
      "        [-0.3944,  0.8510],\n",
      "        [-0.5627,  0.4252],\n",
      "        [ 0.9932,  0.4820],\n",
      "        [-0.7260, -0.9729],\n",
      "        [ 0.4409,  0.0234],\n",
      "        [ 0.6249,  0.7272],\n",
      "        [-0.9200,  1.4616],\n",
      "        [ 0.3691,  0.7310],\n",
      "        [ 0.1661,  1.1447]]) tensor([ 1.6076,  0.5161,  1.6301,  4.5370,  6.0586,  4.9968,  2.9787, -2.6004,\n",
      "         2.4506,  0.6347])\n"
     ]
    }
   ],
   "source": [
    "for x_2,y_2 in data_iter_1:\n",
    "    print(x_2,y_2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f01e1",
   "metadata": {},
   "source": [
    "#### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b2de93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(torch.nn.Module):\n",
    "    def __init__(self,n_feature):\n",
    "        super(LinearNet,self).__init__()\n",
    "        self.linear = Linear(n_feature,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ade1649f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNet(\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以用nn.Sequential来更加方便地搭建网络\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(num_inputs,1),\n",
    "# )\n",
    "model = LinearNet(num_inputs)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "536a3214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0659,  0.4888]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1405], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 通过 model.parameters() 来查看模型所有的可学习参数，此函数将返回一个生成器\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af646c1",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "085bcd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.normal_(model.linear.weight,mean=0,std=0.01)\n",
    "init.constant_(model.linear.bias,val=0) # constant_ : 使用val的值来填充输入的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1cbe163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.0107,  0.0083]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight,model.linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79712634",
   "metadata": {},
   "source": [
    "#### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9abf426",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a88e91",
   "metadata": {},
   "source": [
    "#### 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5ca2914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.03\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.03)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ba747f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为不同子网络设置不同的学习率\n",
    "# optimizer =optim.SGD([\n",
    "#                 # 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "#                 {'params': model.subnet1.parameters()}, # lr=0.03\n",
    "#                 {'params': model.subnet2.parameters(), 'lr': 0.01}\n",
    "#             ], lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc3415",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cef4c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 10.359767\n",
      "epoch 1, loss: 9.789368\n",
      "epoch 2, loss: 9.273485\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for x_3,y_3 in data_iter_1:\n",
    "        y_pre = model(x_3)\n",
    "        loss = loss_fn(y_pre,y_3.view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    l = loss_fn(model(x),y.view(-1,1))\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87dae203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 model 获得需要的层，并访问其权重（weight）和偏差（bias）\n",
    "dense = model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d09ed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] Parameter containing:\n",
      "tensor([[ 0.0744, -0.0288]], requires_grad=True)\n",
      "4.2 Parameter containing:\n",
      "tensor([0.3870], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(true_w,dense.weight)\n",
    "print(true_b,dense.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e479b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
