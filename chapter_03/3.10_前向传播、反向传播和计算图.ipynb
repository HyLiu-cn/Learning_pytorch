{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c77415",
   "metadata": {},
   "source": [
    "### 前向传播（forward propagation）:\n",
    "    按顺序（从输入层到输出层）,依次计算并存储模型的中间变量（包括输出）\n",
    "    \n",
    "    以带权重衰减（L2正则化）的单隐藏层多层感知机上为例。\n",
    "    输入样本为 x ，并且隐藏层不包含偏置项，W1 为隐藏层的权重参数，则中间变量为：\n",
    "![mean_val_1](./img/3.10/mean_val_1.png)\n",
    "    \n",
    "    根据多层感知机可知，中间变量 z 通过激活函数 φ 后，得到隐藏激活向量，这个向量也是中间变量：\n",
    "![mean_val_2](./img/3.10/mean_val_2.png)\n",
    "    \n",
    "    设输出层的参数只有 W2 ，则输出层变量为：\n",
    "![mean_val_3](./img/3.10/mean_val_3.png)\n",
    "    \n",
    "    其中单个数据样本的损失项为：\n",
    "![loss_1](./img/3.10/loss_1.png)\n",
    "    \n",
    "    L2 惩罚项为：\n",
    "![L2](./img/3.10/L2.png)\n",
    "    \n",
    "    即最终数据样本上的正则化损失为：\n",
    "![loss_2](./img/3.10/loss_2.png)\n",
    "\n",
    "    计算图：\n",
    "![graph](./img/3.10/graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adccad8",
   "metadata": {},
   "source": [
    "### 反向传播:\n",
    "    依据微积分中的链式法则，沿着从输出层到输入层的顺序，依次计算并存储目标函数有关神经网络各层的中间变量以及参数的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbb3d2",
   "metadata": {},
   "source": [
    "### 训练深度学习模型:\n",
    "    在训练深度学习模型时，正向传播和反向传播之间相互依赖\n",
    "    \n",
    "    即，正向传播的计算可能依赖于模型参数的当前值，而这些模型参数是在反向传播的梯度计算后通过优化算法迭代的；\n",
    "        反向传播的梯度计算可能依赖于各变量的当前值，而这些变量的当前值是通过正向传播计算得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff6dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
